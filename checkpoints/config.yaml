batch_size: 48
beta1: 0.9
beta2: 0.95
compile_model: true
dataset_bin_pattern: ./data/fineweb10B/*train*.bin
device: auto
dropout: 0.1
eval_interval: 1000
grad_clip: 1.0
gradient_accumulation_steps: 1
hidden_size: 768
learning_rate: 0.0003
log_dir: ./logs
log_interval: 25
max_seq_len: 1024
max_steps: 1750
mixed_precision: true
n_head: 6
n_layer: 12
output_dir: ./checkpoints
sample_interval: 1000
save_interval: 10000
vocab_size: 50257
warmup_steps: 1000
weight_decay: 0.1
