batch_size: 16
beta1: 0.9
beta2: 0.95
compile_model: true
dataset_bin_pattern: ./data/*train*.bin
device: auto
dropout: 0.1
eval_interval: 1000
grad_clip: 1.0
gradient_accumulation_steps: 1
hidden_size: 768
learning_rate: 0.0003
log_dir: ./logs
log_interval: 50
max_seq_len: 1024
max_steps: 1000000
mixed_precision: true
n_head: 12
n_layer: 12
output_dir: ./checkpoints
sample_interval: 1000
save_interval: 10000
vocab_size: 50257
warmup_steps: 1000
weight_decay: 0.1
